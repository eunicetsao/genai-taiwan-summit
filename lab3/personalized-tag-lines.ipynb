{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a AI Sales Agent for Personalized Tag-lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Objective](#Objective)\n",
    "- [Personalized tag-lines given user ID](#personalized-tag-lines-given-user-ID)\n",
    "- [Prompt engineering for the large language model](#Prompt-engineering-for-the-large-language-model)\n",
    "- [Play with the text-to-text mdoel](#play-with-the-text-to-text-language-model)\n",
    "- [Play with the text-to-image mdoel](#play-with-the-text-to-image-mdoel)\n",
    "- [Use Amazon Personalize for product recommendations](#use-amazon-personalize-for-product-recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Generate personalized tag-lines for a user given user profile data and product data.\n",
    "\n",
    "This might be useful in cases where you'd like to get more user engagement with content and so you use Gen AI to focus on specific aspects of that content and create a tag-line that is more relevant/intriguing to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.230 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pprint\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler, SagemakerEndpoint\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure env vars\n",
    "SM_ENDPOINT_NAME_LLM = None # \"<resource arn of a LLM endpoint goes here>\"\n",
    "SM_ENDPOINT_NAME_SD = None # \"<resource arn of a SD endpoint goes here>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the API url and key\n",
    "with open('./config.json', 'r') as json_file:\n",
    "    config_data = json.load(json_file)\n",
    "\n",
    "for key, value in config_data.items():\n",
    "        os.environ[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the notebook on your local IDE, you can set local = True and provide your AWS profile for the account where you have deployed a model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_NAME = 'us-east-1' # default region of the workshop\n",
    "\n",
    "local = True # if True, please fill in AWS_PROFILE and REGION_NAME below\n",
    "if local:\n",
    "    # Configure AWS credentials and profile\n",
    "    AWS_PROFILE = '<AWS_PROFILE>'\n",
    "    REGION_NAME = '<AWS_REGION>'\n",
    "\n",
    "    # Setup session\n",
    "    os.environ[\"AWS_PROFILE\"] = AWS_PROFILE\n",
    "    boto3.setup_default_session(profile_name=AWS_PROFILE, region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load static files into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to get personalized tag-lines for product recommended to a given user, we need to import some initial data about users and products.\n",
    "\n",
    "The `products.csv` file contains relevant metadata about products; features like: category, price, product description, etc...\n",
    "\n",
    "The `users.csv` file contains user information like their age and gender description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user metadata\n",
    "users_metadata_df = pd.read_csv('./data/users_retail.csv')\n",
    "\n",
    "# Get product metadata\n",
    "products_metadata_df = pd.read_csv('./data/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personalized tag-lines given user ID \n",
    "\n",
    "Given the user id and one selected product for that user, we'll see how our model generates tag-lines and product posts for that specific user.\n",
    "\n",
    "You can try to change the user id and see how tag-lines and posts will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User info\n",
    "user_id = 1473 # 5919, 491, 1473\n",
    "age_description, gender_description = get_user(user_id, users_metadata_df)\n",
    "user_info_text = f'The user is in age {age_description} and {gender_description}'\n",
    "\n",
    "print(user_info_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Product info\n",
    "product_metadata_dict = get_product(\"575c0ac0-5494-4c64-a886-a9c0cf8b779a\", products_metadata_df) # 575c0ac0-5494-4c64-a886-a9c0cf8b779a\n",
    "\n",
    "print('Prodcut info:')\n",
    "pprint.pprint(product_metadata_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt engineering for the large language model\n",
    "\n",
    "Changing the prompt can indeed influence the generated words. If you'd like to proceed with a different prompt to generate a new marketing slogan, feel free to test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "    Create a marketing ads for a product. You want the ads to impress the user, so make it appealing to them based on the information of the user and the product.\n",
    " \n",
    "    \n",
    "    {user_info_text}\n",
    "\n",
    "    Here is the product information:\n",
    "    {product_metadata_dict}\n",
    "\n",
    "    Here is the marketing ads: <p>\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_info_text\", \"product_metadata_dict\"],\n",
    "    template=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the text-to-text language model\n",
    "\n",
    "In the lab, we adopt Falcon-40B to help us with the text-to-text tasks. Falcon-40B is open-source and has demonstrated its effectiveness in various applications, including natural language processing, machine translation, and text generation.\n",
    "\n",
    "Here, we adopt two ways to query the model:\n",
    "\n",
    "1. Deployment through Amazon SageMaker within your account, utilizing the langchain library to obtain results by providing the endpoint information.\n",
    "\n",
    "2. Sending API requests with the provided API key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1. Deployment through Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create content handler\n",
    "class FalconContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        parameters = {\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.9,\n",
    "            \"temperature\": 0.8,\n",
    "            \"max_new_tokens\": 1024,\n",
    "            \"stop\": [\"\\n\\n<|endoftext|>\", \"</s>\", \"</p>\"]\n",
    "        }\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": parameters})\n",
    "\n",
    "        return input_str.encode('utf-8')\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = output.read()\n",
    "        res = json.loads(response_json)\n",
    "\n",
    "        return res[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SM_ENDPOINT_NAME_LLM:\n",
    "\n",
    "    # Create model\n",
    "    llm = SagemakerEndpoint(\n",
    "        endpoint_name=SM_ENDPOINT_NAME_LLM,\n",
    "        region_name=REGION_NAME,\n",
    "        content_handler=FalconContentHandler()\n",
    "    )\n",
    "\n",
    "    # Query llm with langchain\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    response_llm = chain({\n",
    "        \"user_info_text\":user_info_text,\n",
    "        \"product_metadata_dict\":product_metadata_dict\n",
    "    })\n",
    "\n",
    "    response_intermediate = response_llm['text']\n",
    "    print(response_intermediate)\n",
    "else:\n",
    "    print(\"No SageMaker endpoint available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2. Sending API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps({\n",
    "      \"user_info_text\": user_info_text,\n",
    "      \"product_metadata_dict\": product_metadata_dict\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_llm = requests.post(\n",
    "    os.environ[\"LLM_API_URL\"],\n",
    "    headers={ \n",
    "        'accept': 'application/json',\n",
    "        'X-API-Key': os.environ[\"LLM_KEY\"]\n",
    "    },\n",
    "    data=data\n",
    ")\n",
    "\n",
    "response_intermediate = json.loads(response_llm.content.decode('utf-8'))['message']\n",
    "response_intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the text-to-image mdoel \n",
    "\n",
    "Here we adopt Stable Diffusion v2-1-base model to do text-to-image task. For more details, please visit the [Huggine Face website](https://huggingface.co/stabilityai/stable-diffusion-2-1-base).\n",
    "\n",
    "We also adopt two ways to query the model:\n",
    "\n",
    "1. Deployment through Amazon SageMaker within your account, invoking the SageMaker endpoint.\n",
    "\n",
    "2. Call an Amazon SageMaker model endpoint via Amazon API Gateway and AWS Lambda with the provided API key.\n",
    "\n",
    "\n",
    "**Design the prompt and config model parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: You can play with the text-to-image model by modify the prompt below\n",
    "# response_intermediate = \"your prompt goes here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images with stable diffusion model \n",
    "request_body = {\n",
    "    \"prompt\": response_intermediate,\n",
    "    \"num_images_per_prompt\": 1,\n",
    "    \"num_inference_steps\": 10,\n",
    "}\n",
    "\n",
    "payload = json.dumps(request_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1. Deployment through Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SM_ENDPOINT_NAME_SD:\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "    response_sd = client.invoke_endpoint(\n",
    "        EndpointName=SM_ENDPOINT_NAME_SD,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=payload,\n",
    "    )\n",
    "\n",
    "    response_str = response_sd[\"Body\"].read().decode('utf-8')\n",
    "    response = json.loads(response_str)\n",
    "else:\n",
    "    print(\"No SageMaker endpoint available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2. Sending API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_sd = requests.post(\n",
    "    os.environ[\"SD_API_URL\"],\n",
    "    headers={ \n",
    "        'accept': 'application/json',\n",
    "        'X-API-Key': os.environ[\"SD_KEY\"]\n",
    "    },\n",
    "    data=payload\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_str = response_sd.content.decode('utf-8')\n",
    "response = json.loads(response_str)['message']\n",
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image post processing \n",
    "def parse_response_multiple_images(response_dict):\n",
    "    \"\"\"Parse response and return generated image and the prompt\"\"\"\n",
    "    return response_dict[\"generated_images\"], response_dict[\"prompt\"]\n",
    "\n",
    "def display_img_and_prompt(img, prmpt):\n",
    "    \"\"\"Display hallucinated image.\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images, input_prompt = parse_response_multiple_images(response)\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, input_prompt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Amazon Personalize for product recommendations\n",
    "\n",
    "Now one way you might improve recommendations is to get an initial set of products for a particular user via a model - instead of just randomly choosing products. You can use our Amazon Personalize service to get this initial, more personalized, list of products.\n",
    "\n",
    "You don't have to build the model youself. We build the model for you and you simply and API requests to get product recommendations.\n",
    "\n",
    "Alternatively, we have a static file that represents data we got from Amazon Personalize if you just want to run through this notebook without using Amazon Personalize. All you need to do is set `use_personalize_api` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = user_id\n",
    "product_recommendations = get_product_recommendations(\n",
    "    user_id=user_id, \n",
    "    use_personalize_api=True, \n",
    "    api_key=os.environ[\"P13N_KEY\"],\n",
    "    api_endpoint_name=os.environ[\"P13N_API_URL\"]\n",
    ")\n",
    "print(f'AWS Personalize API recommendations: {product_recommendations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use these products' IDs given from Amazon Personalize to get personalized tag-line recommendations for a given user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_llm(user_info_text, product_metadata_dict):\n",
    "    \n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    \n",
    "    # Payload of LLM\n",
    "    data = json.dumps({\n",
    "        \"user_info_text\": user_info_text,\n",
    "        \"product_metadata_dict\": product_metadata_dict\n",
    "    })\n",
    "    \n",
    "    # Invoke text-to-text model\n",
    "    response_llm = requests.post(\n",
    "        os.environ[\"LLM_API_URL\"],\n",
    "        headers={ \n",
    "            'accept': 'application/json',\n",
    "            'X-API-Key': os.environ[\"LLM_KEY\"]\n",
    "        },\n",
    "        data=data\n",
    "    )\n",
    "    response = json.loads(response_llm.content.decode('utf-8'))\n",
    " \n",
    "    # Generate images with sd model \n",
    "    request_body = {\n",
    "        \"prompt\": response['message'],\n",
    "        \"num_images_per_prompt\": 1,\n",
    "        \"num_inference_steps\": 10,\n",
    "    }\n",
    "    \n",
    "    # Payload of SD\n",
    "    payload = json.dumps(request_body)\n",
    "    \n",
    "    # Invoke text-to-image model\n",
    "    response_sd = requests.post(\n",
    "        os.environ[\"SD_API_URL\"],\n",
    "        headers={ \n",
    "            'accept': 'application/json',\n",
    "            'X-API-Key': os.environ[\"SD_KEY\"]\n",
    "        },\n",
    "        data=payload\n",
    "    )\n",
    "\n",
    "    response_str = response_sd.content.decode('utf-8')\n",
    "    response = json.loads(response_str)['message']\n",
    "    \n",
    "    # Plot generated images\n",
    "    generated_images, input_prompt = parse_response_multiple_images(response)\n",
    "    for img in generated_images:\n",
    "        display_img_and_prompt(img, input_prompt) \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate product posts for recommended products for the target user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'll do is loop through each product recommendation and fetch information about it from our local static data, join it with our user data, and get generative, personalized tag-line predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for product_recommendation_id in product_recommendations:\n",
    "    # User info\n",
    "    age_description, favorite_genres = get_user(user_id, users_metadata_df)\n",
    "    user_info_text = f'The user is in age {age_description} and {gender_description}'\n",
    "\n",
    "    # Product info\n",
    "    product_metadata_dict = get_product(product_recommendation_id, products_metadata_df)\n",
    "\n",
    "    print(f'User info:\\n{user_info_text}\\n')\n",
    "    print(f'Product {product_recommendation_id} info:')\n",
    "    pprint.pprint(product_metadata_dict)\n",
    "\n",
    "    # Invoke model\n",
    "    invoke_llm(user_info_text, product_metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
