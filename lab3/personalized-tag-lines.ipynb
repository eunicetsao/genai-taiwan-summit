{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a AI Sales Agent for Personalized Tag-lines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workshop uses SageMaker Notebook, and please ensure the kernel is set to **conda_python3**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [1. Objective](#1-Objective)\n",
    "- [2. Personalized tag-lines given user ID](#2-personalized-tag-lines-given-user-ID)\n",
    "- [3. Prompt engineering for the large language model](#3-Prompt-engineering-for-the-large-language-model)\n",
    "- [4. Play with the text-to-text mdoel](#4-play-with-the-text-to-text-language-model)\n",
    "- [5. Play with the text-to-image mdoel](#5-play-with-the-text-to-image-mdoel)\n",
    "- [6. Use Amazon Personalize for product recommendations](#6-use-amazon-personalize-for-product-recommendations)\n",
    "- [7. Generate product posts for recommended products for the target user](#7-generate-product-posts-for-recommended-products-for-the-target-user)\n",
    "- [8. Using SDXL 1.0 with AWS JumpStart](#8-using-sdxl-1.0-with-aws-jumpstart)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Objective\n",
    "\n",
    "Generate personalized tag-lines for a user given user profile data and product data.\n",
    "\n",
    "This might be useful in cases where you'd like to get more user engagement with content and so you use Gen AI to focus on specific aspects of that content and create a tag-line that is more relevant/intriguing to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.230 --quiet\n",
    "!pip install Pillow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import pprint\n",
    "import time\n",
    "import requests\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Dict\n",
    "from PIL import Image\n",
    "from helpers import *\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import AmazonAPIGateway\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler, SagemakerEndpoint\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the API url and key\n",
    "with open('./config.json', 'r') as json_file:\n",
    "    config_data = json.load(json_file)\n",
    "\n",
    "for key, value in config_data.items():\n",
    "        os.environ[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the notebook on your local IDE, you can set local = True and provide your AWS profile for the account where you have deployed a model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_NAME = 'us-east-1' # default region of the workshop\n",
    "\n",
    "local = False # if True, please fill in AWS_PROFILE and REGION_NAME below\n",
    "if local:\n",
    "    # Configure AWS credentials and profile\n",
    "    AWS_PROFILE = '<AWS_PROFILE>'\n",
    "    REGION_NAME = '<AWS_REGION>'\n",
    "\n",
    "    # Setup session\n",
    "    os.environ[\"AWS_PROFILE\"] = AWS_PROFILE\n",
    "    boto3.setup_default_session(profile_name=AWS_PROFILE, region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load static files into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to get personalized tag-lines for product recommended to a given user, we need to import some initial data about users and products.\n",
    "\n",
    "The `products.csv` file contains relevant metadata about products; features like: category, price, product description, etc...\n",
    "\n",
    "The `users.csv` file contains user information like their age and gender description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user metadata\n",
    "users_metadata_df = pd.read_csv('./data/users_retail.csv')\n",
    "\n",
    "# Get product metadata\n",
    "products_metadata_df = pd.read_csv('./data/products.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Personalized tag-lines given user ID \n",
    "\n",
    "Given the user id and one selected product for that user, we'll see how our model generates tag-lines and product posts for that specific user.\n",
    "\n",
    "You can try to change the user id and see how tag-lines and posts will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User info\n",
    "user_id = 4018\n",
    "age_description, gender_description = get_user(user_id, users_metadata_df)\n",
    "user_info_text = f'The user is in age {age_description} and {gender_description}'\n",
    "\n",
    "print(user_info_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Product info\n",
    "product_metadata_dict = get_product(\"575c0ac0-5494-4c64-a886-a9c0cf8b779a\", products_metadata_df) # 575c0ac0-5494-4c64-a886-a9c0cf8b779a\n",
    "\n",
    "print('Prodcut info:')\n",
    "pprint.pprint(product_metadata_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prompt engineering for the large language model\n",
    "\n",
    "Changing the prompt can indeed influence the generated words. If you'd like to proceed with a different prompt to generate a new marketing slogan, feel free to test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "    Create a marketing ads for a product. You want the ads to impress the user, so make it appealing to them based on the information of the user and the product.\n",
    " \n",
    "    \n",
    "    {user_info_text}\n",
    "\n",
    "    Here is the product information:\n",
    "    {product_metadata_dict}\n",
    "\n",
    "    Here is the marketing ads: <p>\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_info_text\", \"product_metadata_dict\"],\n",
    "    template=prompt_template\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Play with the text-to-text language model\n",
    "\n",
    "In the lab, we adopt Falcon-40B to help us with the text-to-text tasks. Falcon-40B is open-source and has demonstrated its effectiveness in various applications, including natural language processing, machine translation, and text generation.\n",
    "\n",
    "Here, we adopt two ways to query the model:\n",
    "\n",
    "[`Method 1`] Deployment through Amazon SageMaker within your account, utilizing the langchain library to obtain results by providing the endpoint information.\n",
    "\n",
    "[`Method 2`] Sending API requests with the provided API key.\n",
    "\n",
    "For method 1, please set up the endpoint in your Workshop Studio account for your Large Language Model (LLM) and the endpoint for your Stable Diffusion (SD) model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure env vars\n",
    "SM_ENDPOINT_NAME_LLM = None # \"<resource arn of a LLM endpoint goes here>\"\n",
    "SM_ENDPOINT_NAME_SD = None # \"<resource arn of a SD endpoint goes here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1. Deployment through Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create content handler\n",
    "class FalconContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        parameters = {\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.9,\n",
    "            \"temperature\": 0.8,\n",
    "            \"max_new_tokens\": 1024,\n",
    "            \"stop\": [\"\\n\\n<|endoftext|>\", \"</s>\", \"</p>\"]\n",
    "        }\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": parameters})\n",
    "\n",
    "        return input_str.encode('utf-8')\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = output.read()\n",
    "        res = json.loads(response_json)\n",
    "\n",
    "        return res[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SM_ENDPOINT_NAME_LLM:\n",
    "\n",
    "    # Create model\n",
    "    llm = SagemakerEndpoint(\n",
    "        endpoint_name=SM_ENDPOINT_NAME_LLM,\n",
    "        region_name=REGION_NAME,\n",
    "        content_handler=FalconContentHandler()\n",
    "    )\n",
    "\n",
    "    # Query llm with langchain\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    response_llm = chain({\n",
    "        \"user_info_text\":user_info_text,\n",
    "        \"product_metadata_dict\":product_metadata_dict\n",
    "    })\n",
    "\n",
    "    response_intermediate = response_llm['text']\n",
    "    response_intermediate = remove_html_tags(response_intermediate)\n",
    "    print(response_intermediate)\n",
    "else:\n",
    "    print(\"No SageMaker endpoint available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2. Sending API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps({\n",
    "      \"user_info_text\": user_info_text,\n",
    "      \"product_metadata_dict\": product_metadata_dict\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_llm = requests.post(\n",
    "    os.environ[\"LLM_API_URL\"],\n",
    "    headers={ \n",
    "        'accept': 'application/json',\n",
    "        'X-API-Key': os.environ[\"LLM_KEY\"]\n",
    "    },\n",
    "    data=data\n",
    ")\n",
    "\n",
    "response_intermediate = json.loads(response_llm.content.decode('utf-8'))['message']\n",
    "response_intermediate = remove_html_tags(response_intermediate)\n",
    "response_intermediate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Play with the text-to-image mdoel \n",
    "\n",
    "Here we adopt Stable Diffusion v2-1-base model to do text-to-image task. For more details, please visit the [Huggine Face website](https://huggingface.co/stabilityai/stable-diffusion-2-1-base).\n",
    "\n",
    "We also adopt two ways to query the model:\n",
    "\n",
    "1. Deployment through Amazon SageMaker within your account, invoking the SageMaker endpoint.\n",
    "\n",
    "2. Call an Amazon SageMaker model endpoint via Amazon API Gateway and AWS Lambda with the provided API key.\n",
    "\n",
    "\n",
    "**Design the prompt and config model parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images with stable diffusion model \n",
    "request_body = {\n",
    "    \"prompt\": response_intermediate,\n",
    "    \"num_images_per_prompt\": 1,\n",
    "    \"num_inference_steps\": 10,\n",
    "}\n",
    "\n",
    "payload = json.dumps(request_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1. Deployment through Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SM_ENDPOINT_NAME_SD:\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "    response_sd = client.invoke_endpoint(\n",
    "        EndpointName=SM_ENDPOINT_NAME_SD,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=payload,\n",
    "    )\n",
    "\n",
    "    response_str = response_sd[\"Body\"].read().decode('utf-8')\n",
    "    response = json.loads(response_str)\n",
    "else:\n",
    "    print(\"No SageMaker endpoint available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2. Sending API requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_sd = requests.post(\n",
    "    os.environ[\"SD_API_URL\"],\n",
    "    headers={ \n",
    "        'accept': 'application/json',\n",
    "        'X-API-Key': os.environ[\"SD_KEY\"]\n",
    "    },\n",
    "    data=payload\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_str = response_sd.content.decode('utf-8')\n",
    "response = json.loads(response_str)['message']\n",
    "#response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image post processing \n",
    "def parse_response_multiple_images(response_dict):\n",
    "    \"\"\"Parse response and return generated image and the prompt\"\"\"\n",
    "    return response_dict[\"generated_images\"], response_dict[\"prompt\"]\n",
    "\n",
    "def display_img_and_prompt(img, prompt):\n",
    "    \"\"\"Display hallucinated image.\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(np.array(img))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images, input_prompt = parse_response_multiple_images(response)\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, input_prompt) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use Amazon Personalize for product recommendations\n",
    "\n",
    "Now one way you might improve recommendations is to get an initial set of products for a particular user via a model - instead of just randomly choosing products. You can use our Amazon Personalize service to get this initial, more personalized, list of products.\n",
    "\n",
    "You don't have to build the model youself. We build the model for you and you simply and API requests to get product recommendations.\n",
    "\n",
    "Alternatively, we have a static file that represents data we got from Amazon Personalize if you just want to run through this notebook without using Amazon Personalize. All you need to do is set `use_personalize_api` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = user_id\n",
    "product_recommendations = get_product_recommendations(\n",
    "    user_id=user_id, \n",
    "    use_personalize_api=True, \n",
    "    api_key=os.environ[\"P13N_KEY\"],\n",
    "    api_endpoint_name=os.environ[\"P13N_API_URL\"]\n",
    ")\n",
    "print(f'AWS Personalize API recommendations: {product_recommendations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use these products' IDs given from Amazon Personalize to get personalized tag-line recommendations for a given user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_llm(user_info_text, product_metadata_dict):\n",
    "    \n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    \n",
    "    # Payload of LLM\n",
    "    data = json.dumps({\n",
    "        \"user_info_text\": user_info_text,\n",
    "        \"product_metadata_dict\": product_metadata_dict\n",
    "    })\n",
    "    \n",
    "    # Invoke text-to-text model\n",
    "    response_llm = requests.post(\n",
    "        os.environ[\"LLM_API_URL\"],\n",
    "        headers={ \n",
    "            'accept': 'application/json',\n",
    "            'X-API-Key': os.environ[\"LLM_KEY\"]\n",
    "        },\n",
    "        data=data\n",
    "    )\n",
    "    response = json.loads(response_llm.content.decode('utf-8'))['message']\n",
    "    response = remove_html_tags(response)\n",
    " \n",
    "    # Generate images with sd model \n",
    "    request_body = {\n",
    "        \"prompt\": response,\n",
    "        \"num_images_per_prompt\": 1,\n",
    "        \"num_inference_steps\": 40,\n",
    "    }\n",
    "    \n",
    "    # Payload of SD\n",
    "    payload = json.dumps(request_body)\n",
    "    \n",
    "    # Invoke text-to-image model\n",
    "    response_sd = requests.post(\n",
    "        os.environ[\"SD_API_URL\"],\n",
    "        headers={ \n",
    "            'accept': 'application/json',\n",
    "            'X-API-Key': os.environ[\"SD_KEY\"]\n",
    "        },\n",
    "        data=payload\n",
    "    )\n",
    "\n",
    "    response_str = response_sd.content.decode('utf-8')\n",
    "    response = json.loads(response_str)['message']\n",
    "    \n",
    "    # Plot generated images\n",
    "    generated_images, input_prompt = parse_response_multiple_images(response)\n",
    "    for img in generated_images:\n",
    "        display_img_and_prompt(img, input_prompt) \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generate product posts for recommended products for the target user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'll do is loop through each product recommendation and fetch information about it from our local static data, join it with our user data, and get generative, personalized tag-line predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for product_recommendation_id in product_recommendations:\n",
    "    # User info\n",
    "    age_description, favorite_genres = get_user(user_id, users_metadata_df)\n",
    "    user_info_text = f'The user is in age {age_description} and {gender_description}'\n",
    "\n",
    "    # Product info\n",
    "    product_metadata_dict = get_product(product_recommendation_id, products_metadata_df)\n",
    "\n",
    "    print(f'User info:\\n{user_info_text}\\n')\n",
    "    print(f'Product {product_recommendation_id} info:')\n",
    "    pprint.pprint(product_metadata_dict)\n",
    "\n",
    "    # Invoke model\n",
    "    invoke_llm(user_info_text, product_metadata_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Using SDXL 1.0 with AWS JumpStart\n",
    "\n",
    "Let's dive into the capabilities of Stable Diffusion XL 1.0, a powerful AI model created by Stability AI with Amazon SageMaker JumpStart.\n",
    "\n",
    "Now, here's what you can do with this model:\n",
    "\n",
    "[`TODO 1`] Compare with the previous session using the samem prompt: You can use the same description you gave earlier with the LLM to see how Stable Diffusion XL 1.0 interprets it. This will allow you to compare the two models' abilities in generating images based on the same prompt.\n",
    "\n",
    "[`TODO 2`] Explore model diversity with seed values: Try adjusting the \"seed\" value, which is like a random number that affects how the model generates images. By changing the seed, you'll get different interpretations of the same prompt. It's a fun way to see how the model's creativity can vary with just a small change.\n",
    "\n",
    "[`TODO 3`] Create your own prompt: You can play around and describe any scene or concept you want the model to generate an image for. For example, you can ask the model to create \"A peaceful beach with palm trees and a beautiful sunset.\" Let your imagination run wild and see what the model comes up with!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images with stable diffusion model \n",
    "def generate_image_with_sdxl(prompt, seed):\n",
    "    # prepare payload\n",
    "    request_body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"seed\": seed,\n",
    "        \"style_preset\": \"photographic\",\n",
    "        \"cfg_scale\": 4,\n",
    "        \"sampler\": \"K_DPM_2_ANCESTRAL\"\n",
    "    }\n",
    "    payload = json.dumps(request_body)\n",
    "\n",
    "    # send API request\n",
    "    response_sdxl = requests.post(\n",
    "        os.environ[\"SDXL_API_URL\"],\n",
    "        headers={ \n",
    "            'content': 'image/png',\n",
    "            'accept': 'image/png',\n",
    "            'X-API-Key': os.environ[\"SD_KEY\"]\n",
    "        },\n",
    "        data=payload\n",
    "    )\n",
    "    display(Image.open(io.BytesIO(response_sdxl.content)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I provide two sample prompts for you to generate a bag for men:\n",
    "\n",
    "Prompt 1 :\n",
    "```{txt}\n",
    "Enjoy a flavorful and nutritious meal with our lentil stew with potatos, carrots and spices. With its super healthy ingredients, this dish will delight your palate and satisfy your appetite. It's the perfect meal for a cold winter day, so try it now and discover the joy of our lentil stew!\n",
    "```\n",
    "\n",
    "Prompt 2 :\n",
    "```{txt}\n",
    "This black bag for men is the perfect companion for any occasion. With its durable material and stylish design, it's guaranteed to impress anyone who sees it. Made from high-quality leather, this bag is built to last and withstand daily wear and tear. Its spacious interior allows you to carry all your daily essentials, such as your laptop, wallet, phone, and more. With its adjustable strap, you can carry it over your shoulder or across your body, making it comfortable to carry for extended periods of time. Whether you're going to work or just out running errands, this bag is the perfect accessory to complete your look. Don't hesitate and grab one today!\n",
    "\n",
    "Overall, this code should help you create a marketing campaign that appeals to your target audience based on their demographics and interests.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1 : Compare with the previous session using the samem prompt\n",
    "prompt_sdxl = response_intermediate\n",
    "seed = 12345\n",
    "\n",
    "generate_image_with_sdxl(prompt=prompt_sdxl, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2 : Explore model diversity with seed values\n",
    "prompt_sdxl = response_intermediate\n",
    "seed = 1234 # \"your prompt seed here\"\n",
    " \n",
    "generate_image_with_sdxl(prompt=prompt_sdxl, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3 : Create your own prompt\n",
    "prompt_sdxl = \"boy\" # \"your prompt goes here\"\n",
    "seed = 1234\n",
    "\n",
    "generate_image_with_sdxl(prompt=prompt_sdxl, seed=seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
