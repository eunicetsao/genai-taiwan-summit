{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca678442",
   "metadata": {},
   "source": [
    "## Install the required library\n",
    "\n",
    "To utilize the `langchian` library, we must execute the pip command to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dae96b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e2ca2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain import SQLDatabaseChain, SQLDatabase\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e29ba5",
   "metadata": {},
   "source": [
    "## Prepare the endpoint\n",
    "\n",
    "In the previous step, you might aleady deploy a large language model for this exercise. \n",
    "\n",
    "Please copy your endpoint name here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32337beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = '[Your Endpoint name]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5963289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0fdae4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    region_name='us-east-1',\n",
    "    model_kwargs={\"temperature\": 0.01, \"max_new_tokens\": 200},\n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f7bf5e",
   "metadata": {},
   "source": [
    "### Set up a cross account profile(Expreiments)\n",
    "\n",
    "As with the previous steps, it is also feasible to perform cross-account testing by attempting to access another Sagemaker Endpoint.\n",
    "\n",
    "To call the endpoint from another AWS account, you need to create an AWS credentials profile. For instance, you can set up a profile named `cross_account_endpoint`\n",
    "\n",
    "```commandline\n",
    "sh-4.2$ aws configure --profile cross_account_endpoint\n",
    "AWS Access Key ID [None]: [Your Access ID]\n",
    "AWS Secret Access Key [None]: [Your Secret Access Key]\n",
    "Default region name [None]: us-east-1\n",
    "Default output format [None]: json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95418f3",
   "metadata": {},
   "source": [
    "Verify your account profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a6a4a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "!aws configure get region --profile cross_account_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0acb4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    credentials_profile_name='cross_account_endpoint',\n",
    "    region_name='us-east-1',\n",
    "    model_kwargs={\"temperature\": 0.01, \"max_new_tokens\": 200},\n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c1bd3",
   "metadata": {},
   "source": [
    "## Get the database connection\n",
    "\n",
    "In this example, we connect to an athena database.\n",
    "\n",
    "We use the SQLAlchemy https://pypi.org/project/SQLAlchemy/ and pyathena https://pypi.org/project/pyathena/ as the connector to our database.\n",
    "\n",
    "\n",
    "Please visit the Cloudformation console and find your `ATHENA_BUCKET`\n",
    "\n",
    "![alt athena_bucket](cloudformation_sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b5f2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATHENA_BUCKET = 'genai-text-to-sql-workshop'\n",
    "ATHENA_DATABASE = 'genai-text-to-sql-workshop'\n",
    "ATHENA_REGION = 'us-east-1'\n",
    "conn_str = f\"awsathena+rest://:@athena.{ATHENA_REGION}.amazonaws.com:443/{ATHENA_DATABASE}?s3_staging_dir=s3://{ATHENA_BUCKET}/Unsaved/\"\n",
    "database_engine = create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71677c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = SQLDatabase(database_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858ead0",
   "metadata": {},
   "source": [
    "## Try a SQLDatabaseChain\n",
    "\n",
    "A chain can be described as a wrapper that encompasses several individual components, creating a unified end-to-end process with a fixed sequence of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b232351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SQLDatabaseChain chain...\u001B[0m\n",
      "what is total sales amount of product Fruits\n",
      "SQLQuery:\u001B[32;1m\u001B[1;3mSELECT sum(price) FROM sales WHERE product = 'Fruits'\u001B[0m\n",
      "SQLResult: \u001B[33;1m\u001B[1;3m[(31728.5,)]\u001B[0m\n",
      "Answer:\u001B[32;1m\u001B[1;3m[31728.5]\u001B[0m\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"what is total sales amount of product Fruits\"\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, data_base, verbose=True)\n",
    "\n",
    "result = db_chain(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09cb52e",
   "metadata": {},
   "source": [
    "## Add Insights\n",
    "\n",
    "Sometimes, we do not only need a data, we need to know the meaning of the data. Here you can customized your own sql process and generate insights using langchian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c1525",
   "metadata": {},
   "source": [
    "### Creat your own SQL process\n",
    "\n",
    "You can extend the current SQLDatabaseChain to customize your own process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9fdd2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, Optional, List\n",
    "\n",
    "from langchain import SQLDatabaseChain, PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain.chains.sql_database.base import INTERMEDIATE_STEPS_KEY\n",
    "\n",
    "\n",
    "class SQLDatabaseChainWithInsight(SQLDatabaseChain):\n",
    "    return_intermediate_steps: bool = True\n",
    "\n",
    "    def _call(\n",
    "            self,\n",
    "            inputs: Dict[str, Any],\n",
    "            run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        input_text = f\"{inputs[self.input_key]}\\nSQLQuery:\"\n",
    "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
    "        # If not present, then defaults to None which is all tables.\n",
    "        table_names_to_use = inputs.get(\"table_names_to_use\")\n",
    "        table_info = self.database.get_table_info(table_names=table_names_to_use)\n",
    "        llm_inputs = {\n",
    "            \"input\": input_text,\n",
    "            \"top_k\": str(self.top_k),\n",
    "            \"dialect\": self.database.dialect,\n",
    "            \"table_info\": table_info,\n",
    "            \"stop\": [\"\\nSQLResult:\"],\n",
    "        }\n",
    "        intermediate_steps: List = []\n",
    "        try:\n",
    "            intermediate_steps.append(llm_inputs)  # input: sql generation\n",
    "            sql_cmd = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "\n",
    "            _run_manager.on_text(sql_cmd, color=\"green\", verbose=self.verbose)\n",
    "            intermediate_steps.append(\n",
    "                sql_cmd\n",
    "            )  # output: sql generation (no checker)\n",
    "            intermediate_steps.append({\"sql_cmd\": sql_cmd})  # input: sql exec\n",
    "            result = self.database.run(sql_cmd)\n",
    "            intermediate_steps.append(str(result))  # output: sql exec\n",
    "\n",
    "            _run_manager.on_text(\"\\nSQLResult: \", verbose=self.verbose)\n",
    "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
    "            # If return direct, we just set the final result equal to\n",
    "            # the result of the sql query result, otherwise try to get a human readable\n",
    "            # final answer\n",
    "            _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
    "            input_text += f\"{sql_cmd}\\nSQLResult: {result}\\nAnswer:\"\n",
    "            llm_inputs[\"input\"] = input_text\n",
    "            intermediate_steps.append(llm_inputs)  # input: final answer\n",
    "            sql_data = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "            intermediate_steps.append(sql_data)  # output: sql data\n",
    "            _run_manager.on_text(sql_data, color=\"green\", verbose=self.verbose)\n",
    "\n",
    "            GET_INSIGHT = \"\"\"\n",
    "                    You are a senior data analytics.\n",
    "\n",
    "                    Your task is to analyze the given company data in JSON format and provide insights or explanations for any trends or patterns observed. The data pertains to the question: \n",
    "                    {question}.\n",
    "                    Your response should be clear and concise, no more than 200 words.\n",
    "\n",
    "                    Response data: {data}\n",
    "\n",
    "                    Please note that if the data is empty or null, you should simply state \"no insight.\" \n",
    "\n",
    "                    My Insight:\n",
    "                    \"\"\"\n",
    "            get_insight_prompt = PromptTemplate(\n",
    "                template=GET_INSIGHT, input_variables=[\"question\", \"data\"]\n",
    "            )\n",
    "            get_insight_chain = LLMChain(\n",
    "                llm=self.llm_chain.llm, prompt=get_insight_prompt\n",
    "            )\n",
    "\n",
    "            get_insight_inputs = {\n",
    "                \"question\": inputs[self.input_key],\n",
    "                \"data\": result,\n",
    "            }\n",
    "\n",
    "            final_result: str = get_insight_chain.predict(\n",
    "                callbacks=_run_manager.get_child(), **get_insight_inputs\n",
    "            ).strip()\n",
    "\n",
    "            _run_manager.on_text(\"\\nInsights:\", verbose=self.verbose)\n",
    "            _run_manager.on_text(\n",
    "                final_result, color=\"blue\", verbose=self.verbose\n",
    "            )\n",
    "\n",
    "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
    "            if self.return_intermediate_steps:\n",
    "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
    "            return chain_result\n",
    "        except Exception as exc:\n",
    "            # Append intermediate steps to exception, to aid in logging and later\n",
    "            # improvement of few shot prompt seeds\n",
    "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
    "            raise exc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766131e5",
   "metadata": {},
   "source": [
    "### Call your customized chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d826ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SQLDatabaseChainWithInsight chain...\u001B[0m\n",
      "what is total sales amount of product Fruits\n",
      "SQLQuery:\u001B[32;1m\u001B[1;3mSELECT sum(price) FROM sales WHERE product = 'Fruits'\u001B[0m\n",
      "SQLResult: \u001B[33;1m\u001B[1;3m[(31728.5,)]\u001B[0m\n",
      "Answer:\u001B[32;1m\u001B[1;3m[31728.5]\u001B[0m\n",
      "Insights:\u001B[36;1m\u001B[1;3mThe total sales amount of product Fruits is 31728.5.\u001B[0m\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChainWithInsight.from_llm(llm, data_base, verbose=True)\n",
    "result = db_chain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1836af4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
